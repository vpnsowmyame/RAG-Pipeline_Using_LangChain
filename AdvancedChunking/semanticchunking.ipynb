{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50be95ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Win 11\\Desktop\\RAG Pipeline\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f743cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Chunks:\n",
      "Chunk 1:LangChain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
      "Chunk 2:You can create chains, agents, memory, and retrievers.\n",
      "Chunk 3:The Eiffel Tower is located in Paris.\n",
      "Chunk 4:France is a popular tourist destination.\n"
     ]
    }
   ],
   "source": [
    "model=SentenceTransformer('all-MiniLM-L6-v2')\n",
    "## Sample text\n",
    "text=\"\"\"\n",
    "LangChain is a framework for building applications with LLMs.\n",
    "Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
    "You can create chains, agents, memory, and retrievers.\n",
    "The Eiffel Tower is located in Paris.\n",
    "France is a popular tourist destination.\n",
    "\"\"\"\n",
    "## Step 1 : Split into sentences\n",
    "sentences=[s.strip() for s in text.split(\"\\n\") if s.strip()]\n",
    "\n",
    "### Step 2: Embed each sentence\n",
    "embeddings=model.encode(sentences)\n",
    "\n",
    "# Step 3: Initialize parameters\n",
    "threshold = 0.7  # control chunk tightness\n",
    "chunks = []\n",
    "current_chunk=[sentences[0]]\n",
    "\n",
    "## Step 4: Semantic grouping based on threshold\n",
    "\n",
    "for i in range(1, len(sentences)):\n",
    "    sim = cosine_similarity(\n",
    "        [embeddings[i - 1]],\n",
    "        [embeddings[i]]\n",
    "    )[0][0]\n",
    "\n",
    "    if sim>=threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "    else:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk=[sentences[i]]\n",
    "# Append the last chunk\n",
    "chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "# Output the chunks\n",
    "print(\"Semantic Chunks:\")\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {idx+1}:{chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1acb031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RAG Pipeline Modular Coding\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableMap\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7346acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom Semantic Chunker With Threshold\n",
    "\n",
    "class ThresholdSemanticChunker:\n",
    "    def __init__(self,model_name=\"all-MiniLM-L6-v2\",threshold=0.7):\n",
    "        self.model=SentenceTransformer(model_name)\n",
    "        self.threshold=threshold\n",
    "\n",
    "    def split(self, text: str):\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        embeddings = self.model.encode(sentences)\n",
    "        chunks = []\n",
    "        current_chunk = [sentences[0]]\n",
    "\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim = cosine_similarity([embeddings[i - 1]], [embeddings[i]])[0][0]\n",
    "            if sim >= self.threshold:\n",
    "                current_chunk.append(sentences[i])\n",
    "            else:\n",
    "                chunks.append(\". \".join(current_chunk) + \".\")\n",
    "                current_chunk = [sentences[i]]\n",
    "\n",
    "        chunks.append(\". \".join(current_chunk) + \".\")\n",
    "        return chunks\n",
    "\n",
    "    def split_documents(self,docs):\n",
    "        result=[]\n",
    "        for doc in docs:\n",
    "            for chunk in self.split(doc.page_content):\n",
    "                result.append(Document(page_content=chunk, metadata=doc.metadata))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1735e99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='\\n    \"LangChain is a framework for building applications with LLMs.\"\\n    \"Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\"\\n    \"You can create chains, agents, memory, and retrievers.\"\\n    \"The Eiffel Tower is located in Paris.\"\\n    \"France is a popular tourist destination.\"\\n    ')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample text\n",
    "sample_text = \"\"\"\n",
    "    \"LangChain is a framework for building applications with LLMs.\"\n",
    "    \"Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\"\n",
    "    \"You can create chains, agents, memory, and retrievers.\"\n",
    "    \"The Eiffel Tower is located in Paris.\"\n",
    "    \"France is a popular tourist destination.\"\n",
    "    \"\"\"\n",
    "doc = Document(page_content=sample_text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae425ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='\"LangChain is a framework for building applications with LLMs. \"\\n    \"Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.'),\n",
       " Document(metadata={}, page_content='\"\\n    \"You can create chains, agents, memory, and retrievers.'),\n",
       " Document(metadata={}, page_content='\"\\n    \"The Eiffel Tower is located in Paris.'),\n",
       " Document(metadata={}, page_content='\"\\n    \"France is a popular tourist destination.'),\n",
       " Document(metadata={}, page_content='\".')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chunking\n",
    "chunker=ThresholdSemanticChunker(threshold=0.7)\n",
    "chunks=chunker.split_documents([doc])\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bd6924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VectorStore\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "embedding=OpenAIEmbeddings()\n",
    "vectorstore=FAISS.from_documents(chunks,embedding)\n",
    "retriever=vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b0fae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based on the following context:\\n    {context}\\n    Question: {question}\\n    ')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt Template\n",
    "template = \"\"\"Answer the question based on the following context:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c1a9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000002469134F590>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002469134F620>, root_client=<openai.OpenAI object at 0x0000024691263E60>, root_async_client=<openai.AsyncOpenAI object at 0x000002469134E240>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models.base import init_chat_model\n",
    "llm=init_chat_model(\"openai:gpt-3.5-turbo\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ed0ebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework used for building applications with Large Language Models (LLMs). It provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n"
     ]
    }
   ],
   "source": [
    "### LCEL Chain With retrieval\n",
    "rag_chain=(\n",
    "        RunnableMap(\n",
    "            {\n",
    "            \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "            \"question\": lambda x: x[\"question\"],\n",
    "            }\n",
    "        )\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "query = {\"question\": \"What is LangChain used for?\"}\n",
    "result = rag_chain.invoke(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bb28bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fb539db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " chunk 1:\n",
      "LangChain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
      "\n",
      " chunk 2:\n",
      "You can create chains, agents, memory, and retrievers. The Eiffel Tower is located in Paris. France is a popular tourist destination.\n"
     ]
    }
   ],
   "source": [
    "## Load the documents\n",
    "loader=TextLoader(\"langchain_intro.txt\")\n",
    "docs=loader.load()\n",
    "\n",
    "## Initialize embedding model\n",
    "embedding=OpenAIEmbeddings()\n",
    "\n",
    "## Create the semantic chunker\n",
    "chunker=SemanticChunker(embedding)\n",
    "\n",
    "## Split the documents\n",
    "chunks=chunker.split_documents(docs)\n",
    "\n",
    "## Result\n",
    "\n",
    "for i,chunk in enumerate(chunks):\n",
    "    print(f\"\\n chunk {i+1}:\\n{chunk.page_content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG udemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
